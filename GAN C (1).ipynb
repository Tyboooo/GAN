{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a5708e-ff3f-490f-a218-44604924ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoaderm\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from deepface import DeepFace\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "latent_dim = 100\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "lr = 0.0002\n",
    "betas = (0.5, 0.999) \n",
    "\n",
    "celeba_root = r\"C:\\Users\\thiba\\Downloads\\archive\\img_align_celeba\"\n",
    "vanilla_image_dir = \"vanilla_gan_images\"\n",
    "os.makedirs(vanilla_image_dir, exist_ok=True)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "dataset = datasets.ImageFolder(root=celeba_root, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "class VanillaGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VanillaGenerator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 64 * 64 * 3),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.model(z)\n",
    "        return out.view(-1, 3, 64, 64)\n",
    "\n",
    "class VanillaDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VanillaDiscriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(64 * 64 * 3, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.model(img.view(img.size(0), -1))\n",
    "\n",
    "def train_gan(generator, discriminator, dataloader, epochs, latent_dim, lr=0.0002, betas=(0.5, 0.999), run_name=\"GAN\"):\n",
    "    criterion = nn.BCELoss()\n",
    "    optim_G = optim.Adam(generator.parameters(), lr=lr, betas=betas)\n",
    "    optim_D = optim.Adam(discriminator.parameters(), lr=lr, betas=betas)\n",
    "\n",
    "    generator.to(device)\n",
    "    discriminator.to(device)\n",
    "\n",
    "    generator_losses = []\n",
    "    discriminator_losses = []\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        g_loss_epoch = 0.0\n",
    "        d_loss_epoch = 0.0\n",
    "\n",
    "        for i, (imgs, _) in enumerate(dataloader):\n",
    "            batch_size_curr = imgs.size(0)\n",
    "            real_labels = torch.ones(batch_size_curr, 1, device=device)\n",
    "            fake_labels = torch.zeros(batch_size_curr, 1, device=device)\n",
    "            real_imgs = imgs.to(device)\n",
    "            z = torch.randn(batch_size_curr, latent_dim, device=device)\n",
    "            fake_imgs = generator(z)\n",
    "            d_real = discriminator(real_imgs)\n",
    "            d_real_loss = criterion(d_real, real_labels)\n",
    "            d_fake = discriminator(fake_imgs.detach())\n",
    "            d_fake_loss = criterion(d_fake, fake_labels)\n",
    "            d_loss = d_real_loss + d_fake_loss\n",
    "            optim_D.zero_grad()\n",
    "            d_loss.backward()\n",
    "            optim_D.step()\n",
    "            g_output = discriminator(fake_imgs)\n",
    "            g_loss = criterion(g_output, real_labels)\n",
    "            optim_G.zero_grad()\n",
    "            g_loss.backward()\n",
    "            optim_G.step()\n",
    "            d_loss_epoch += d_loss.item()\n",
    "            g_loss_epoch += g_loss.item()\n",
    "        d_loss_epoch /= len(dataloader)\n",
    "        g_loss_epoch /= len(dataloader)\n",
    "        discriminator_losses.append(d_loss_epoch)\n",
    "        generator_losses.append(g_loss_epoch)\n",
    "        print(f\"[{run_name}] Epoch [{epoch}/{epochs}] \"\n",
    "              f\"D Loss: {d_loss_epoch:.4f} | G Loss: {g_loss_epoch:.4f}\")\n",
    "        \n",
    "    return generator_losses, discriminator_losses\n",
    "\n",
    "def plot_training_losses(generator_losses, discriminator_losses, approach_name):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(generator_losses, label=\"Generator Loss\")\n",
    "    plt.plot(discriminator_losses, label=\"Discriminator Loss\")\n",
    "    plt.title(f\"Training Losses ({approach_name})\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "vanilla_generator = VanillaGenerator(latent_dim)\n",
    "vanilla_discriminator = VanillaDiscriminator()\n",
    "vanilla_g_losses, vanilla_d_losses = train_gan(\n",
    "    vanilla_generator,\n",
    "    vanilla_discriminator,\n",
    "    dataloader,\n",
    "    epochs=epochs,\n",
    "    latent_dim=latent_dim,\n",
    "    lr=lr,\n",
    "    betas=betas,\n",
    "    run_name=\"VanillaGAN\"\n",
    ")\n",
    "\n",
    "plot_training_losses(vanilla_g_losses, vanilla_d_losses, \"Vanilla GAN\")\n",
    "\n",
    "vanilla_generator.eval()\n",
    "with torch.no_grad():\n",
    "    num_to_generate = 300\n",
    "    total_batches = num_to_generate // batch_size\n",
    "    count = 0\n",
    "    for _ in range(total_batches):\n",
    "        z = torch.randn(batch_size, latent_dim, device=device)\n",
    "        gen_imgs = vanilla_generator(z)\n",
    "        for img in gen_imgs:\n",
    "            count += 1\n",
    "            save_path = os.path.join(vanilla_image_dir, f\"image_{count}.png\")\n",
    "            save_image(img, save_path, normalize=True)\n",
    "    remainder = num_to_generate % batch_size\n",
    "    if remainder > 0:\n",
    "        z = torch.randn(remainder, latent_dim, device=device)\n",
    "        gen_imgs = vanilla_generator(z)\n",
    "        for img in gen_imgs:\n",
    "            count += 1\n",
    "            save_path = os.path.join(vanilla_image_dir, f\"image_{count}.png\")\n",
    "            save_image(img, save_path, normalize=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac3da82-864b-4a30-9913-3dbb82ce9ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from deepface import DeepFace\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def analyze_images_deepface_cached(image_dir, csv_path=\"deepface_analysis.csv\", enforce_detection=False):\n",
    "    if os.path.exists(csv_path):\n",
    "        print(f\"[Cache] Loading cached DeepFace results from {csv_path}\")\n",
    "        return pd.read_csv(csv_path)\n",
    "    rows = []\n",
    "    for img_file in image_files:\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        try:\n",
    "            analysis = DeepFace.analyze(\n",
    "                img_path,\n",
    "                actions=['age','gender','emotion','race'], \n",
    "                enforce_detection=enforce_detection\n",
    "            )\n",
    "            \n",
    "            if isinstance(analysis, list):\n",
    "                if len(analysis) == 0:\n",
    "                    print(f\"[DeepFace] No face data for {img_path}\")\n",
    "                    continue\n",
    "                analysis = analysis[0]\n",
    "                \n",
    "            age = analysis['age']\n",
    "            gdata = analysis['gender']\n",
    "            if isinstance(gdata, dict):\n",
    "                gkey = max(gdata, key=gdata.get)\n",
    "            else:\n",
    "                gkey = gdata\n",
    "            gkey = gkey.lower()\n",
    "            gender = 1 if \"man\" in gkey else 0\n",
    "\n",
    "            emotion_probs = analysis['emotion']\n",
    "            emotion = max(emotion_probs, key=emotion_probs.get)\n",
    "\n",
    "            race_probs = analysis['race']\n",
    "            race = max(race_probs, key=race_probs.get)\n",
    "\n",
    "            rows.append([img_file, age, gender, emotion, race])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[DeepFace] Error analyzing {img_path}: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=['image','age','gender','emotion','race'])\n",
    "    print(f\"[Cache] Saving DeepFace results to {csv_path}\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    return df\n",
    "\n",
    "def find_optimal_k_elbow_silhouette(data_array, min_k=2, max_k=10):\n",
    "    k_values = range(min_k, max_k+1)\n",
    "    inertias = []\n",
    "    silhouettes = []\n",
    "\n",
    "    for k in k_values:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42).fit(data_array)\n",
    "        inertia = kmeans.inertia_\n",
    "        labels = kmeans.labels_\n",
    "        sil = silhouette_score(data_array, labels)\n",
    "        inertias.append(inertia)\n",
    "        silhouettes.append(sil)\n",
    "        \n",
    "    plt.figure()\n",
    "    plt.plot(k_values, inertias, 'o--')\n",
    "    plt.title(\"Elbow Method (Inertia vs. k)\")\n",
    "    plt.xlabel(\"k\")\n",
    "    plt.ylabel(\"Inertia (Sum of Squared Distances)\")\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "    plt.plot(k_values, silhouettes, 'o--', color='orange')\n",
    "    plt.title(\"Silhouette Score vs. k\")\n",
    "    plt.xlabel(\"k\")\n",
    "    plt.ylabel(\"Average Silhouette\")\n",
    "    plt.show()\n",
    "\n",
    "    return list(k_values), inertias, silhouettes\n",
    "\n",
    "def cluster_data(data_array, n_clusters=5):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(data_array)\n",
    "    return clusters, kmeans\n",
    "\n",
    "def plot_feature_distributions(features_df, approach_name):\n",
    "    if 'age' in features_df.columns:\n",
    "        plt.figure()\n",
    "        sns.histplot(features_df['age'].dropna(), kde=True)\n",
    "        plt.title(f\"Age Distribution ({approach_name})\")\n",
    "        plt.xlabel(\"Age\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.show()\n",
    "\n",
    "    if 'gender' in features_df.columns:\n",
    "        plt.figure()\n",
    "        sns.countplot(x='gender', data=features_df.dropna(subset=['gender']))\n",
    "        plt.title(f\"Gender Distribution ({approach_name})\")\n",
    "        plt.xlabel(\"Gender (0=Female, 1=Male)\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.show()\n",
    "\n",
    "    if 'emotion' in features_df.columns:\n",
    "        plt.figure()\n",
    "        order_emotion = features_df['emotion'].value_counts().index\n",
    "        sns.countplot(x='emotion', data=features_df.dropna(subset=['emotion']), order=order_emotion)\n",
    "        plt.title(f\"Emotion Distribution ({approach_name})\")\n",
    "        plt.xlabel(\"Emotion\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "\n",
    "    if 'race' in features_df.columns:\n",
    "        plt.figure()\n",
    "        order_race = features_df['race'].value_counts().index\n",
    "        sns.countplot(x='race', data=features_df.dropna(subset=['race']), order=order_race)\n",
    "        plt.title(f\"Race Distribution ({approach_name})\")\n",
    "        plt.xlabel(\"Race\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "\n",
    "def plot_cluster_compositions(features_df, approach_name):\n",
    "    if 'cluster' not in features_df.columns:\n",
    "        return\n",
    "\n",
    "    if 'age' in features_df.columns:\n",
    "        plt.figure()\n",
    "        sns.boxplot(x='cluster', y='age', data=features_df.dropna(subset=['age']))\n",
    "        plt.title(f\"Age Distribution by Cluster ({approach_name})\")\n",
    "        plt.xlabel(\"Cluster\")\n",
    "        plt.ylabel(\"Age\")\n",
    "        plt.show()\n",
    "\n",
    "    if 'gender' in features_df.columns:\n",
    "        plt.figure()\n",
    "        gender_cluster = features_df.dropna(subset=['gender']).groupby(['cluster','gender']).size().unstack(fill_value=0)\n",
    "        gender_cluster.plot(kind='bar', stacked=True, figsize=(8,5))\n",
    "        plt.title(f\"Gender Composition by Cluster ({approach_name})\")\n",
    "        plt.xlabel(\"Cluster\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.show()\n",
    "\n",
    "    if 'emotion' in features_df.columns:\n",
    "        plt.figure()\n",
    "        sns.countplot(x='cluster', hue='emotion', data=features_df.dropna(subset=['emotion']))\n",
    "        plt.title(f\"Emotion Composition by Cluster ({approach_name})\")\n",
    "        plt.xlabel(\"Cluster\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.legend(title=\"Emotion\")\n",
    "        plt.show()\n",
    "\n",
    "    if 'race' in features_df.columns:\n",
    "        plt.figure()\n",
    "        sns.countplot(x='cluster', hue='race', data=features_df.dropna(subset=['race']))\n",
    "        plt.title(f\"Race Composition by Cluster ({approach_name})\")\n",
    "        plt.xlabel(\"Cluster\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.legend(title=\"Race\")\n",
    "        plt.show()\n",
    "\n",
    "def plot_cluster_centers(kmeans, data_array, approach_name, feature_names=None):\n",
    "    if feature_names is None:\n",
    "        feature_names = [f\"feature_{i}\" for i in range(data_array.shape[1])]\n",
    "    if data_array.shape[1] > 10:\n",
    "        print(\"[Warning] Too many features for a neat heatmap. Skipping.\")\n",
    "        return\n",
    "\n",
    "    centers = kmeans.cluster_centers_\n",
    "    centers_df = pd.DataFrame(centers, columns=feature_names)\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.heatmap(centers_df, cmap=\"YlGnBu\", annot=True, fmt=\".2f\")\n",
    "    plt.title(f\"Cluster Centers Heatmap ({approach_name})\")\n",
    "    plt.xlabel(\"Features\")\n",
    "    plt.ylabel(\"Cluster\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_pca_projection(data_array, features_df, approach_name):\n",
    "    if 'cluster' not in features_df.columns:\n",
    "        return\n",
    "\n",
    "    valid_idx = features_df.dropna(subset=['cluster']).index\n",
    "    data_sub = data_array[valid_idx]\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_result = pca.fit_transform(data_sub)\n",
    "\n",
    "    temp_df = features_df.loc[valid_idx].copy()\n",
    "    temp_df['pca1'] = pca_result[:, 0]\n",
    "    temp_df['pca2'] = pca_result[:, 1]\n",
    "\n",
    "    plt.figure()\n",
    "    sns.scatterplot(x='pca1', y='pca2', hue='cluster', data=temp_df, palette='viridis')\n",
    "    plt.title(f\"PCA Projection of Clusters ({approach_name})\")\n",
    "    plt.xlabel(\"PCA 1\")\n",
    "    plt.ylabel(\"PCA 2\")\n",
    "    plt.show()\n",
    "\n",
    "def calculate_cluster_averages(features_df):\n",
    "    def mode(series):\n",
    "        return series.value_counts().index[0]\n",
    "\n",
    "    if 'cluster' not in features_df.columns:\n",
    "        return None\n",
    "\n",
    "    agg_dict = {}\n",
    "    if 'age' in features_df.columns:\n",
    "        agg_dict['age'] = 'mean'\n",
    "    if 'gender' in features_df.columns:\n",
    "        agg_dict['gender'] = 'mean'\n",
    "    if 'emotion' in features_df.columns:\n",
    "        agg_dict['emotion'] = mode\n",
    "    if 'race' in features_df.columns:\n",
    "        agg_dict['race'] = mode\n",
    "\n",
    "    cluster_stats = features_df.groupby('cluster').agg(agg_dict).reset_index()\n",
    "    print(cluster_stats)\n",
    "    return cluster_stats\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_dir = r\"C:\\Users\\thiba\\vanilla_gan_images\"\n",
    "\n",
    "    df = analyze_images_deepface_cached(image_dir, csv_path=\"deepface_analysis.csv\", enforce_detection=False)\n",
    "    print(\"Sample of DeepFace analysis:\\n\", df.head())\n",
    "\n",
    "    df_numeric = df[['age','gender']].copy()\n",
    "    df_numeric = df_numeric.dropna()\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(df_numeric)  \n",
    "\n",
    "    k_values, inertias, silhouettes = find_optimal_k_elbow_silhouette(data_scaled, min_k=2, max_k=10)\n",
    "    best_k = 5\n",
    "\n",
    "    clusters, kmeans = cluster_data(data_scaled, n_clusters=best_k)\n",
    "\n",
    "    valid_idx = df_numeric.index\n",
    "    cluster_series = pd.Series(clusters, index=valid_idx, name='cluster')\n",
    "    df_final = df.join(cluster_series, how='left')\n",
    "\n",
    "    plot_feature_distributions(df_final, \"MyGAN - DeepFace\")\n",
    "    plot_cluster_compositions(df_final, \"MyGAN - DeepFace\")\n",
    "    plot_cluster_centers(kmeans, data_scaled, \"MyGAN - DeepFace\", feature_names=[\"Age\",\"Gender\"])\n",
    "    plot_pca_projection(data_scaled, df_final, \"MyGAN - DeepFace\")\n",
    "    _ = calculate_cluster_averages(df_final)\n",
    "\n",
    "    out_csv = \"mygan_deepface_clusters.csv\"\n",
    "    df_final.to_csv(out_csv, index=False)\n",
    "    print(f\"\\nResults saved to {out_csv} ===\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
